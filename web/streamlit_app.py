# ---------------------
# ì‹¤í–‰ ë°©ë²•
# ---------------------
# # api ì„œë²„ (í”„ë¡œì íŠ¸ rootì—ì„œ ì‹¤í–‰)
# python -m uvicorn src.api.api:app --reload --port 8000
# # UI (web ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰)
# python -m streamlit run .\streamlit_app.py

from __future__ import annotations

import os
from contextlib import contextmanager

import os
import json
import time
import requests
import pandas as pd
import streamlit as st
import pymysql

# ---------------------
# ë¡œë”©ë§ˆìŠ¤í¬
# ---------------------
@contextmanager
def tiny_loading(text: str = "ë¡œë”© ì¤‘..."):
    ph = st.empty()
    ph.markdown(
        f"""
        <style>
        .tiny-loader {{
            display:inline-flex; align-items:center; gap:8px;
            padding:6px 10px; border-radius:9999px;
            background:rgba(0,0,0,0.08); font-size:13px;
        }}
        .tiny-spinner {{
            width:14px; height:14px; border-radius:50%;
            border:2px solid rgba(0,0,0,0.15);
            border-top-color: rgba(0,0,0,0.6);
            animation: tiny-rot 0.8s linear infinite;
        }}
        @keyframes tiny-rot {{ to {{ transform: rotate(360deg); }} }}
        </style>
        <span class="tiny-loader">
          <span class="tiny-spinner"></span>{text}
        </span>
        """,
        unsafe_allow_html=True,
    )
    try:
        yield
    finally:
        ph.empty()

# ---------------------
# ì„¤ì •
# ---------------------
st.set_page_config(page_title="ìŒì•… ì¶”ì²œ", layout="wide")

DEFAULT_API_BASE = os.environ.get("API_BASE", "http://localhost:8000")
API_BASE_DEFAULT = st.secrets.get("API_BASE", DEFAULT_API_BASE)

# DB ì„¤ì •
DB_CFG = dict(
    host=os.environ.get("MYSQL_HOST", "114.203.195.166"),
    user=os.environ.get("MYSQL_USER", "root"),
    password=os.environ.get("MYSQL_PASSWORD", "root"),
    database=os.environ.get("MYSQL_DB", "mlops"),
    port=int(os.environ.get("MYSQL_PORT", "3306")),
    charset="utf8mb4",
)

# (ì„ íƒ) íŒŒì¼ í´ë°± ë¡œê·¸ ê²½ë¡œ
FILE_FALLBACK_LOG = os.environ.get("RECO_LOG_FALLBACK", "./logs/reco_logs.csv")

# ==============================
# ì•± ë ˆì´ì•„ì›ƒ
# ==============================
st.title("ğŸµ Tune for You ë‹¹ì‹ ì„ ìœ„í•œ ìŒì•… ì¶”ì²œ")

api_col = st.container()
with api_col:
    API_BASE = st.text_input(
        "API_BASE",
        value=API_BASE_DEFAULT,
        help="ì˜ˆ: http://localhost:8000",
    ).strip()

tab1, tab2 = st.tabs(["ğŸ¶ ìŒì•… ì¶”ì²œ", "ğŸ“Š í’ˆì§ˆ ëª¨ë‹ˆí„°ë§"])

# ---------------------
# Helpers
# ---------------------
def call_search(api_base: str, by: str, query: str, limit: int = 50) -> pd.DataFrame:
    """Backend /search í˜¸ì¶œ (APIì— /search ì—”ë“œí¬ì¸íŠ¸ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)"""
    url = f"{api_base.rstrip('/')}/search"
    payload = {"by": by, "query": query, "limit": int(limit)}
    resp = requests.post(url, json=payload, timeout=2000)
    resp.raise_for_status()
    items = resp.json().get("items", [])
    return pd.DataFrame(items)

def call_recommend(api_base: str, by: str, query: str, top_k: int, seed_max: int | None = 1) -> pd.DataFrame:
    """Backend /recommend í˜¸ì¶œ"""
    url = f"{api_base.rstrip('/')}/recommend_ranked"
    payload = {"by": by, "query": query, "top_k": int(top_k)}
    if seed_max is not None:
        payload["seed_max"] = int(seed_max)  # ëª¨ë¸ íŒ¨ì¹˜ ì‹œ ì‚¬ìš©
    resp = requests.post(url, json=payload, timeout=2000)
    resp.raise_for_status()
    items = resp.json().get("items", [])
    return pd.DataFrame(items)

# ---------------------
# íƒ­ 1: ìŒì•… ì¶”ì²œ í™”ë©´ (API í˜¸ì¶œ)
# 1) ê²€ìƒ‰
# ---------------------
with tab1:
    # st.header("1) ìŒì•… ê²€ìƒ‰")

    query_by_map = {"ë…¸ë˜ ì œëª©": "track_name", "ê°€ìˆ˜ ì´ë¦„": "artist_name"}
    col1, col2 = st.columns([1, 3])
    with col1:
        query_by_label = st.selectbox("ê²€ìƒ‰ ê¸°ì¤€", list(query_by_map.keys()), index=0)
        query_by = query_by_map[query_by_label]
    with col2:
        query_text = st.text_input("ê²€ìƒ‰ì–´", placeholder="ë…¸ë˜ ì œëª© ë˜ëŠ” ê°€ìˆ˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")

    # í‘œì‹œ ê°œìˆ˜ â†’ ë‚´ë¶€ ê¸°ë³¸ê°’ ì‚¬ìš©
    SEARCH_LIMIT = 50

    if st.button("ê²€ìƒ‰"):
        if not query_text.strip():
            st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            try:
                with tiny_loading("ê²€ìƒ‰ ì¤‘..."):
                    t0 = time.time()
                    df_search = call_search(API_BASE, query_by, query_text, SEARCH_LIMIT)
                    elapsed = time.time() - t0
                if df_search.empty:
                    st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ({elapsed:.3f}ì´ˆ)")
                    st.session_state["search_df"] = None
                else:
                    st.session_state["search_df"] = df_search
                    st.success(f"ì´ {len(df_search)}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ({elapsed:.3f}ì´ˆ)")
            except requests.exceptions.ConnectionError:
                st.error(f"APIì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {API_BASE}")
            except requests.exceptions.HTTPError as e:
                st.error(f"API ì˜¤ë¥˜: {e.response.status_code} {e.response.text}")
            except Exception as e:
                st.exception(e)

    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ & í‘œì—ì„œ í–‰ ì„ íƒ
    df_search = st.session_state.get("search_df", None)
    selected_seed_id = None

    if isinstance(df_search, pd.DataFrame) and not df_search.empty:
        st.subheader("ê²€ìƒ‰ ê²°ê³¼")

        display_cols = [c for c in ["track_name", "artist_name"] if c in df_search.columns]
        if not display_cols:
            display_cols = [c for c in df_search.columns if c != "track_id"]

        # ì›ë³¸ ì¸ë±ìŠ¤ë¥¼ ìœ ì§€í•˜ì—¬ ì„ íƒ í–‰ì—ì„œ track_idë¥¼ ì—­ì¶”ì 
        temp = df_search[display_cols].copy()
        temp.insert(0, "ì„ íƒ", False)

        edited = st.data_editor(
            temp,
            use_container_width=True,
            hide_index=True,
            num_rows="fixed",
            disabled=[c for c in temp.columns if c != "ì„ íƒ"],
            column_config={
                "ì„ íƒ": st.column_config.CheckboxColumn(
                    "ì„ íƒ",
                    help="ì¶”ì²œì„ ìƒì„±í•  ê³¡ì„ í•œ ê³¡ë§Œ ì„ íƒí•˜ì„¸ìš”",
                    default=False,
                    required=False,
                )
            },
            key="search_table",
        )

        # ë‹¨ì¼ ì„ íƒ ê°•ì œ: ì—¬ëŸ¬ ê°œ ì²´í¬ë˜ë©´ ê²½ê³ 
        selected_rows = edited.index[edited["ì„ íƒ"] == True].tolist()
        if len(selected_rows) > 1:
            st.warning("í•œ ê³¡ë§Œ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        elif len(selected_rows) == 1:
            if "track_id" in df_search.columns:
                selected_seed_id = df_search.loc[selected_rows[0], "track_id"]
                st.session_state["selected_seed_id"] = selected_seed_id
            else:
                st.warning("ë°±ì—”ë“œ ì‘ë‹µì— track_idê°€ ì—†ì–´ ì‹œë“œ ì„ íƒì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ---------------------
    # 2) ì„ íƒí•œ ê³¡ìœ¼ë¡œ ì¶”ì²œ ìƒì„±
    # ---------------------
    # st.header("2) ì„ íƒí•œ ê³¡ìœ¼ë¡œ ì¶”ì²œ ìƒì„±")

    # top_k = st.slider("ìƒìœ„ Kê°œ", min_value=1, max_value=100, value=10, step=1)
    top_k = 10
    if st.button("ì¶”ì²œí•´ì¤˜!"):
        seed_id = st.session_state.get("selected_seed_id")
        if not seed_id:
            st.warning("ë¨¼ì € ê²€ìƒ‰ ê²°ê³¼ í‘œì—ì„œ ê³¡ì„ í•˜ë‚˜ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        else:
            try:
                with tiny_loading("ì¶”ì²œ ìƒì„± ì¤‘..."):
                    t0 = time.time()
                    df_rec = call_recommend(API_BASE, by="track_id", query=seed_id, top_k=top_k, seed_max=1)
                    elapsed = time.time() - t0
                if df_rec.empty:
                    st.info("ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.success(f"ì´ {len(df_rec)}ê±´ì˜ ì¶”ì²œì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ({elapsed:.3f}ì´ˆ)")
                    prefer = [c for c in ["rank", "track_name", "artist_name", "distance"] if c in df_rec.columns]
                    other = [c for c in df_rec.columns if c not in prefer and c != "track_id"]
                    st.dataframe(df_rec[prefer + other], use_container_width=True, hide_index=True)
            except requests.exceptions.ConnectionError:
                st.error(f"APIì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {API_BASE}")
            except requests.exceptions.HTTPError as e:
                st.error(f"API ì˜¤ë¥˜: {e.response.status_code} {e.response.text}")
            except Exception as e:
                st.exception(e)

# ==============================
# íƒ­ 2: í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ (MySQL â†’ íŒŒì¼ í´ë°±)
# ==============================
with tab2:
    st.header("ì¶”ì²œ í’ˆì§ˆ ëŒ€ì‹œë³´ë“œ")

    df = pd.DataFrame()
    db_err = None
    try:
        con = pymysql.connect(**DB_CFG)
        df = pd.read_sql("SELECT * FROM recommend_logs ORDER BY id DESC LIMIT 200", con)
    except Exception as e:
        db_err = e
    finally:
        try:
            con.close()
        except Exception:
            pass

    if df.empty and db_err is not None:
        st.warning(f"DBì—ì„œ ë¡œê·¸ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {db_err}")
        # íŒŒì¼ í´ë°± ì‹œë„
        if os.path.exists(FILE_FALLBACK_LOG):
            try:
                df = pd.read_csv(FILE_FALLBACK_LOG)
                st.info(f"íŒŒì¼ í´ë°± ë¡œê·¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {FILE_FALLBACK_LOG}")
            except Exception as e:
                st.error(f"í´ë°± ë¡œê·¸ë„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

    if df.empty:
        st.info("ì•„ì§ ë¡œê·¸ê°€ ì—†ì–´ìš”. ë¨¼ì € ì¶”ì²œì„ í•œ ë²ˆ ì‹¤í–‰í•´ ë³´ì„¸ìš”.")
    else:
        # ìŠ¤í‚¤ë§ˆ ì •ë¦¬: ts(datetime), elapsed_sec(float), seed/returned(JSON ë˜ëŠ” ë¬¸ìì—´)
        if "ts" in df.columns:
            df["ts"] = pd.to_datetime(df["ts"], errors="coerce")
        elif "ts_utc" in df.columns:
            df["ts"] = pd.to_datetime(df["ts_utc"], errors="coerce")
        else:
            # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ ê¸°ì¤€ ê°€ì§œì‹œê°„
            df["ts"] = pd.to_datetime(pd.Timestamp.now())

        df["elapsed_sec"] = pd.to_numeric(df.get("elapsed_sec"), errors="coerce")

        def parse_json_maybe(x):
            if isinstance(x, list):
                return x
            if isinstance(x, str):
                try:
                    return json.loads(x)
                except Exception:
                    # íŒŒì´í”„(|)ë¡œ í•©ì¹œ íŒŒì¼ í´ë°± í¬ë§·ì¼ ìˆ˜ ìˆìŒ
                    if "|" in x:
                        return [t for t in x.split("|") if t]
            return []

        df["seed_track_ids"] = df.get("seed_track_ids", []).apply(parse_json_maybe) if "seed_track_ids" in df.columns else [[]]*len(df)
        df["returned_track_ids"] = df.get("returned_track_ids", []).apply(parse_json_maybe) if "returned_track_ids" in df.columns else [[]]*len(df)

        # ë‹¤ì–‘ì„± ì§€í‘œ: ê³ ìœ  ì¶”ì²œ ìˆ˜ / ì „ì²´ ì¶”ì²œ ìˆ˜
        def calc_diversity(lst):
            try:
                return len(set(lst)) / max(len(lst), 1)
            except Exception:
                return None

        df["diversity"] = df["returned_track_ids"].apply(calc_diversity)

        # ë³´ì—¬ì£¼ê¸°
        st.subheader("ìš”ì•½")
        c1, c2, c3 = st.columns(3)
        c1.metric("í‰ê·  ë‹¤ì–‘ì„±", f"{pd.to_numeric(df['diversity'], errors='coerce').mean():.3f}")
        c2.metric("í‰ê·  ì§€ì—°ì‹œê°„(ì´ˆ)", f"{pd.to_numeric(df['elapsed_sec'], errors='coerce').mean():.3f}")
        c3.metric("ì´ ì¶”ì²œ ìˆ˜", len(df))

        st.subheader("ë‹¤ì–‘ì„± ì¶”ì´")
        div_series = df.set_index("ts")["diversity"].dropna()
        if not div_series.empty:
            st.line_chart(div_series)
        else:
            st.caption("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        st.subheader("ì§€ì—°ì‹œê°„ ì¶”ì´")
        lat_series = df.set_index("ts")["elapsed_sec"].dropna()
        if not lat_series.empty:
            st.line_chart(lat_series)
        else:
            st.caption("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        st.subheader("ìµœê·¼ ì¶”ì²œ ë¡œê·¸")
        show_cols = [c for c in ["ts", "by_field", "query", "top_k", "elapsed_sec"] if c in df.columns]
        st.dataframe(df[show_cols].head(30), use_container_width=True)